{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aadd701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the Azure SQL Database successfully!\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "server = 'act4-server.database.windows.net'\n",
    "database = 'act4-database'\n",
    "username = 'stanford'\n",
    "password = 'Hola1234'\n",
    "\n",
    "# Define the connection string for SQL Server (Azure)\n",
    "conn_str = (\n",
    "    f'DRIVER={{ODBC Driver 18 for SQL Server}};'\n",
    "    f'SERVER={server};'\n",
    "    f'DATABASE={database};'\n",
    "    f'UID={username};'\n",
    "    f'PWD={password}'\n",
    ")\n",
    "\n",
    "# Establish the connection\n",
    "try:\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    print(\"Connected to the Azure SQL Database successfully!\")\n",
    "\n",
    "except pyodbc.Error as e:\n",
    "    print(f\"Error connecting to the database: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d78fb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20964\\2608267317.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID  NameStyle Title FirstName MiddleName    LastName Suffix  \\\n",
      "0           1      False   Mr.   Orlando         N.         Gee   None   \n",
      "1           2      False   Mr.     Keith       None      Harris   None   \n",
      "2           3      False   Ms.     Donna         F.    Carreras   None   \n",
      "3           4      False   Ms.     Janet         M.       Gates   None   \n",
      "4           5      False   Mr.      Lucy       None  Harrington   None   \n",
      "\n",
      "                  CompanyName               SalesPerson  \\\n",
      "0                A Bike Store   adventure-works\\pamela0   \n",
      "1          Progressive Sports    adventure-works\\david8   \n",
      "2    Advanced Bike Components  adventure-works\\jillian0   \n",
      "3       Modular Cycle Systems  adventure-works\\jillian0   \n",
      "4  Metropolitan Sports Supply      adventure-works\\shu0   \n",
      "\n",
      "                   EmailAddress         Phone  \\\n",
      "0  orlando0@adventure-works.com  245-555-0173   \n",
      "1    keith0@adventure-works.com  170-555-0127   \n",
      "2    donna0@adventure-works.com  279-555-0130   \n",
      "3    janet1@adventure-works.com  710-555-0173   \n",
      "4     lucy0@adventure-works.com  828-555-0186   \n",
      "\n",
      "                                   PasswordHash PasswordSalt  \\\n",
      "0  L/Rlwxzp4w7RWmEgXX+/A7cXaePEPcp+KwQhl2fJL7w=     1KjXYs4=   \n",
      "1  YPdtRdvqeAhj6wyxEsFdshBDNXxkCXn+CRgbvJItknw=     fs1ZGhY=   \n",
      "2  LNoK27abGQo48gGue3EBV/UrlYSToV0/s87dCRV7uJk=     YTNH5Rw=   \n",
      "3  ElzTpSNbUW1Ut+L5cWlfR7MF6nBZia8WpmGaQPjLOJA=     nm7D5e4=   \n",
      "4  KJqV15wsX3PG8TS5GSddp6LFFVdd3CoRftZM/tP0+R4=     cNFKU4w=   \n",
      "\n",
      "                                rowguid ModifiedDate  \n",
      "0  3F5AE95E-B87D-4AED-95B4-C3797AFCB74F   2005-08-01  \n",
      "1  E552F657-A9AF-4A7D-A645-C429D6E02491   2006-08-01  \n",
      "2  130774B1-DB21-4EF3-98C8-C104BCD6ED6D   2005-09-01  \n",
      "3  FF862851-1DAA-4044-BE7C-3E85583C054D   2006-07-01  \n",
      "4  83905BDC-6F5E-4F71-B162-C98DA069F38A   2006-09-01  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query = \"SELECT * FROM SalesLT.Customer\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "983bca40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomerID               int64\n",
       "NameStyle                 bool\n",
       "Title                   object\n",
       "FirstName               object\n",
       "MiddleName              object\n",
       "LastName                object\n",
       "Suffix                  object\n",
       "CompanyName             object\n",
       "SalesPerson             object\n",
       "EmailAddress            object\n",
       "Phone                   object\n",
       "PasswordHash            object\n",
       "PasswordSalt            object\n",
       "rowguid                 object\n",
       "ModifiedDate    datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "804826bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ModifiedDate'] = pd.to_datetime(df['ModifiedDate'])\n",
    "\n",
    "min_date = df['ModifiedDate'].min()\n",
    "df['ModifiedDateDays'] = (df['ModifiedDate'] - min_date).dt.days\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98cb517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_cols = ['CustomerID', 'CompanyName', 'SalesPerson', 'ModifiedDateDays']\n",
    "df_clean = df[useful_cols].copy()\n",
    "\n",
    "df_clean = pd.get_dummies(df_clean, columns=['CompanyName', 'SalesPerson'], drop_first=True)\n",
    "\n",
    "X = df_clean.drop(columns='ModifiedDateDays')\n",
    "y = df_clean['ModifiedDateDays']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12cc6b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c524a7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.7013708114407509\n",
      "RMSE: 171.4463192754163\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"R2 Score:\", r2_score(y_test, y_pred))\n",
    "print(\"RMSE:\", mean_squared_error(y_test, y_pred, squared=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a2d4f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, 'model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c26f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: The resource group doesn't exist or was not provided. AzureML SDK is creating a resource group=resource_group2 in location=centralindia using subscription=f7573334-1f4f-4ce7-9b75-ce1f32e6bd37.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up past default Resource Group Deployments on the subscription to avoid limit of 10\n",
      "Deleting past Resource Group Deployment with name: DeployResourceGroup-9a4e997089\n",
      "Deploying KeyVault with name workspackeyvault5b835795.\n",
      "Deploying StorageAccount with name workspacstorage1aad7460c.\n",
      "Deploying Workspace with name workspace.\n",
      "Deploying AppInsights with name workspacinsights310f2769.\n",
      "Deployed AppInsights with name workspacinsights310f2769. Took 36.64 seconds.\n",
      "Deployed Workspace with name workspace. Took 41.87 seconds.\n",
      "Registering model model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.create(name=\"workspace\",\n",
    "                      subscription_id = \"f7573334-1f4f-4ce7-9b75-ce1f32e6bd37\",\n",
    "                      resource_group = \"resource_group2\",\n",
    "                      location = \"centralindia\")\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "mname = \"model\"\n",
    "registered_model = Model.register(model_path=\"model.pkl\",\n",
    "                                  model_name=mname,\n",
    "                                  workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e41c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.get(name=\"workspace\",\n",
    "                      subscription_id = \"f7573334-1f4f-4ce7-9b75-ce1f32e6bd37\",\n",
    "                      resource_group = \"resource_group2\",\n",
    "                      location = \"centralindia\")\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "mname = \"model\"\n",
    "registered_model = Model.register(model_path=\"model.pkl\",\n",
    "                                  model_name=mname,\n",
    "                                  workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fce6d648",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorepy = \"\"\"\n",
    "import json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    model_path = Model.get_model_path(\"model\")\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "def run(raw_data):\n",
    "    try:\n",
    "        data = json.loads(raw_data)['data']\n",
    "        df = pd.DataFrame(data)\n",
    "        preds = model.predict(df).tolist()\n",
    "        return json.dumps(preds)\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": str(e)})\n",
    "\"\"\"\n",
    "\n",
    "# Write to file\n",
    "file_score = open(\"score.py\", \"w\")\n",
    "file_score.write(scorepy)\n",
    "file_score.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14feed94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20964\\2091083951.py:18: FutureWarning: azureml.core.model:\n",
      "To leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \n",
      "please refer to respective documentations \n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \n",
      "For more information on migration, see https://aka.ms/acimoemigration \n",
      "To disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n",
      "  service = Model.deploy(\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.model import InferenceConfig, Model\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "virtual_env = Environment(\"env-for-regression\")\n",
    "virtual_env.python.conda_dependencies = CondaDependencies.create(\n",
    "    conda_packages=[\"pandas\", \"scikit-learn\", \"joblib\"]\n",
    ")\n",
    "\n",
    "inference_config = InferenceConfig(\n",
    "    environment=virtual_env,\n",
    "    entry_script=\"score.py\"XX   \n",
    ")\n",
    "\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores=0.5, memory_gb=1)\n",
    "\n",
    "service = Model.deploy(\n",
    "    workspace=ws,\n",
    "    name=\"regression-service\",\n",
    "    models=[registered_model],\n",
    "    inference_config=inference_config,\n",
    "    deployment_config=aci_config,\n",
    "    overwrite=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ccc90aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2025-04-23 17:33:52-06:00 Creating Container Registry if not exists..\n",
      "2025-04-23 17:43:53-06:00 Registering the environment.\n",
      "2025-04-23 17:43:54-06:00 Building image..\n",
      "2025-04-23 17:52:22-06:00 Generating deployment configuration.\n",
      "2025-04-23 17:52:24-06:00 Submitting deployment to compute..\n",
      "2025-04-23 17:52:32-06:00 Checking the status of deployment regression-service..\n",
      "2025-04-23 17:53:48-06:00 Checking the status of inference endpoint regression-service.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "service.wait_for_deployment(show_output=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f061634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "scoring_uri = service.scoring_uri\n",
    "\n",
    "with open(\"uri.json\", \"w\") as file:\n",
    "    json.dump({\"URI\": [scoring_uri]}, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f550c8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_clean = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "X = df_clean.drop(columns=[\"ModifiedDateDays\"])\n",
    "\n",
    "sample_data = X.iloc[[0]] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e52db0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [30.99999999961682]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "data_json = json.dumps({\"data\": sample_data.to_dict(orient=\"records\")})\n",
    "\n",
    "with open(\"uri.json\", \"r\") as f:\n",
    "    scoring_uri = json.load(f)[\"URI\"][0]\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "response = requests.post(scoring_uri, data=data_json, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Prediction:\", json.loads(response.text))\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
